import os
import re
import time
from abc import ABC, abstractmethod
from enum import Enum
from typing import List, Literal, Any

import torch
from pydantic import BaseModel
from tqdm import tqdm

from .. data_model import ModelInstantiationError, BasicLLMConfig, SummaryError
from .. Logger import logger

# Definitions below moved to constants.py -- Forrest, 2025-07-02
# MODEL_FAILED_TO_RETURN_OUTPUT = "MODEL FAILED TO RETURN ANY OUTPUT"
# MODEL_RETURNED_NON_STRING_TYPE_OUTPUT = (
#     "DID NOT RECEIVE A STRING TYPE FROM OUTPUT"
# )
# EMPTY_SUMMARY = (
#     "THIS SUMMARY IS EMPTY, THIS IS THE DEFAULT VALUE A SUMMARY "
#     "VARIABLE GETS. A REAL SUMMARY WAS NOT ASSIGNED TO THIS VARIABLE."
# )
# INCOMPLETE_THINK_TAG = "FOUND <think> WITH NO CLOSING </think>"

# SUMMARY_ERRORS = [
#     MODEL_FAILED_TO_RETURN_OUTPUT,
#     MODEL_RETURNED_NON_STRING_TYPE_OUTPUT,
#     EMPTY_SUMMARY,
#     INCOMPLETE_THINK_TAG
# ]

class AbstractLLM(ABC):
    """
    Abstract Class for an LLM.
    """

    def __init__(self, config: BasicLLMConfig) -> None:
        # Expose all config keys and values as attributes on self
        # for key, value in config.model_dump().items():
        #     setattr(self, key, value)

        self.company = config.company
        self.model_name = config.model_name

        # Set defaults for optional attributes
        # self.prompt = config.prompt if config.prompt is not None else default_prompt
        # self.temperature = config.temperature if config.temperature is not None else 0.0
        # self.max_tokens = config.max_tokens if config.max_tokens is not None else 1024
        # self.min_throttle_time = config.min_throttle_time if config.min_throttle_time is not None else 0.1

        self.prompt = config.prompt
        self.temperature = config.temperature
        self.max_tokens = config.max_tokens
        self.min_throttle_time = config.min_throttle_time

        # The following attributes are not required by all models.
        self.date_code = config.date_code       
        self.thinking_tokens = config.thinking_tokens
        self.execution_mode = config.execution_mode

        if self.date_code not in [None, "", " "]:
            self.model_fullname = f"{self.model_name}-{self.date_code}"
        else:
            self.model_fullname = self.model_name

        self.client: Any | None = None # in case the model can be called via web api
        self.local_model: Any | None = None # in case the model can be run locally

        # self.summary_file: str | None = None # won't be set until after instantiation in summarize.py

    def __enter__(self):
        self.setup() # TODO: Try to skip the setup() and teardown() 
        return self

    def __exit__(self, exc_type, exc_val, exc_t):
        self.teardown()

    def summarize_articles(self, articles: list[str]) -> list[str]:
        """
        Takes in a list of articles, iterates through the list. Returns list of
        the summaries

        Args:
            articles (list[str]): List of strings where the strings are human
            written news articles

        Returns:
            list[str]: List of articles generated by the LLM
        """
        summaries = []
        for article in tqdm(articles, desc="Article Loop"):
            summary = self.summarize_clean_wait(article)
            summaries.append(summary)
        return summaries

    def summarize_clean_wait(self, article: str) -> str:
        """
        Given an article, requests a summary, halts until the minimum time for
        a request is met then cleans the output such that it only contains the 
        summary

        Args:
            article (str): Article text
        
        Returns:
            str: Output from LLM that only contains summary
        """

        start_time = time.time()

        # # Block commented out by Forrest, 2025-07-02
        # raw_summary = self.try_to_summarize_one_article(article)
        # summary = self.clean_raw_summary(raw_summary)
        # summary = self.remove_thinking_text(raw_summary)
        summary = self.try_to_summarize_one_article(article)

        elapsed_time = time.time() - start_time
        remaining_time = self.min_throttle_time - elapsed_time
        if remaining_time > 0:
            time.sleep(remaining_time)

        return summary

    def try_to_summarize_one_article(self, article: str) -> str:
        """
        Tries to request the model to summarize an Article. Logs warnings if it
        fails but continues the program with dummy output indicative of the 
        failure

        Args:
            Article (str): Article to be summarized

        Returns:
            str: Summary of article or dummy string output
        
        """
        # llm_summary = self.summary_error.EMPTY_SUMMARY
        # This line not needed. -- Forrest, 2025-07-02

        # prepared_llm_input = self.prepare_article_for_llm(article)

        prepared_llm_input = self.prompt.format(article=article)

        try:
            # llm_summary = self.summarize_one_article(article)
            llm_summary = self.summarize(prepared_llm_input)
        except Exception as e:
            logger.warning((
                f"Model call failed for {self.model_name}: {e} "
            ))
            return SummaryError.MODEL_FAILED_TO_RETURN_OUTPUT

        if not isinstance(llm_summary, str):
            bad_output = llm_summary
            logger.warning((
                f"{self.model_name} returned unexpected output. Expected a "
                f"string but got {type(bad_output).__name__}. "
                f"Replacing output."
            ))
            return SummaryError.MODEL_RETURNED_NON_STRING_TYPE_OUTPUT
        
        llm_summary = self.remove_thinking_text(llm_summary)

        return llm_summary

    # def summarize_one_article(self, article: str) -> str:
    #     """
    #     Takes in a string representing a human written article, injects a prompt
    #     and feeds into the LLM to generate a summary.

    #     Args:
    #         article (str): String that is a human written news article
        
    #     Returns:
    #         str: A summary of the article generated by the LLM

    #     """
    #     prepared_llm_input = self.prepare_article_for_llm(article)
    #     llm_summary = self.summarize(prepared_llm_input)

    #     return llm_summary

    # def prepare_article_for_llm(self, article: str) -> str:
    #     """
    #     Combines prompt and article for input into an LLM

    #     Args:
    #         text (str): Content text for LLM

    #     Returns:
    #         str: Prompt + content text
    #     """
    #     prepared_text = f"{self.prompt} '{article}'"
    #     return prepared_text

    # def clean_raw_summary(self, raw_summary: str) -> str:
    #     """
    #     Cleans the output summary to only contains relevant summary data

    #     Args:
    #         raw_summary (str): raw_summary output by LLM

    #     Returns:
    #         str: string that only contains summary data
    #     """
    #     summary = self.remove_thinking_text(raw_summary)
    #     if summary in SUMMARY_ERRORS:
    #         return summary
    #     return summary

    def remove_thinking_text(self, raw_summary: str) -> str:
        """
        Removes any thinking tags and content in between them. If a summary does
        not have a closing thinking tag it will be considered as an incomplete 
        summary and return an error string instead.

        TODO: Note that different LLMs may use different tags for thinking. Shall we move to child classes?

        Args:
            raw_summary (str): raw summary from LLM

        returns:
            str: summary without thinking data or invalid summary text

        """
        if '<think>' in raw_summary and '</think>' not in raw_summary:
            logger.warning(f"<think> tag found with no </think>. This is indicative of an incomplete response from an LLM. Raw Summary: {raw_summary}")
            return SummaryError.INCOMPLETE_THINK_TAG

        summary = re.sub(
            r'<think>.*?</think>\s*', '',
            raw_summary, flags=re.DOTALL
        )
        return summary

    # Commented out by Forrest, 2025-07-02
    # Due to too fine grained 
    # def valid_client_model(self) -> bool:
    #     """
    #     If model_name is in client_models list and the model was passed with 
    #     execution mode set to client returns True

    #     Args:
    #         None
    #     Returns:
    #         bool: True if a proper client model
    #     """
    #     if (
    #         self.model_name in self.client_models and 
    #         self.execution_mode == ExecutionMode.CLIENT
    #     ):
    #         return True
    #     else:
    #         return False

    # Commented out by Forrest, 2025-07-02
    # Due to too fine grained 
    # def client_is_defined(self) -> bool:
    #     """
    #     Returns true if self.client is not None

    #     Args:
    #         None
    #     Returns:
    #         bool: True if self.client is not None
    #     """
    #     if self.client is not None:
    #         return True
    #     else:
    #         return False

    # Commented out by Forrest, 2025-07-02
    # def valid_local_model(self) -> bool:
    #     """
    #     If model_name is in local_models list and the model was passed with 
    #     execution mode set to local_model returns True

    #     Args:
    #         None
    #     Returns:
    #         bool: True if a proper client model
    #     """
    #     if (
    #         self.model_name in self.local_models and
    #         self.execution_mode == ExecutionMode.LOCAL
    #     ):
    #         return True
    #     else:
    #         return False
        
    # Commented out by Forrest, 2025-07-02
    # Due to too fine grained 
    # def local_model_is_defined(self) -> bool:
    #     """
    #     Returns true if self.local_model is not None

    #     Args:
    #         None
    #     Returns:
    #         bool: True if self.local_model is not None
    #     """
    #     if self.local_model is not None:
    #         return True
    #     else:
    #         return False

    def default_local_model_teardown(self):
        """
        Standard protcol for tearing down a torch based model, Sets 
        self.local_model to None when done

        Args:
            None
        Returns:
            None
        """
        self.local_model.to("cpu")
        del self.local_model
        torch.cuda.empty_cache()
        self.local_model = None

    # def get_model_identifier(self, model_name: str, date_code: str) -> str:
    #     """
    #     Combines model_name and its date_code if the date_code isn't an emtpy
    #     string otherwise model_name

    #     Args:
    #         model_name (str): base model name
    #         date_code (str): date code of model

    #     Returns:
    #         str: full model identifier
        
    #     """
    #     model = f"{model_name}"
    #     if date_code != "":
    #         model = f"{model_name}-{date_code}"
    #     return model

    # Commented out due to never called and redundant to config files. -- Forrest, 2025-07-02
    # def set_temperature(self, temp: float, reason="no reason given"):
    #     """
    #     Sets temperature, optionally can provide a reason.

    #     Args:
    #         temp (float): temperature
    #         reason (str): reason for changing temp
    #     """
    #     logger.warning(
    #         f"Temperature for {self.model_name} was changed from "
    #         f"{self.temperature} to {temp} because: {reason}"
    #     )
    #     print(
    #         f"Temperature for {self.model_name} was changed from "
    #         f"{self.temperature} to {temp} because: {reason}"
    #     )
    #     self.temperature = temp

    @abstractmethod
    def summarize(self, prepared_text: str) -> str:
        """
        Requests LLM to generate a summary given the input

        Args:
            prepared_text (str): Prompt prepared text

        Returns:
            str: Generated LLM summary
        """
        return None

    @abstractmethod
    def setup(self):
        """
        Setup model for use

        Args:
            None
        Returns:
            None
        """
        return None

    @abstractmethod
    def teardown(self):
        """
        Teardown model

        Args:
            None
        Returns:
            None
        """
        return None

    @abstractmethod
    def close_client(self):
        """
        Close client

        Args:
            None
        Returns:
            None
        """
        return None