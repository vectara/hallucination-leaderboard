# Unused Class
class HHEM:
    """
    Hughes Hallucination Evaluation Model(HHEM)

    Attributes:
        device (str): specifies cpu or gpu compute
        model (torch.nn.Module): loaded HHEM model

    Methods:
        get_scores(articles, summaries): returns all hhem scores for a list
            articles and their respective summaries generated by another model
        get_score(article, summary): returns hhem score for a single article
            summary pair
        predict(article, summary): feeds data into model and returns hhem score
        process_raw_score(torch.Tensor): process raw model output into hhem
            score
        init_model(model_path): loads the model from specified path

    
    """
    def __init__(self, model_path: str, device: str):
        self.device = device
        self.prompt = (
            "<pad> Determine if the hypothesis is true given the premise?\n"
            "Premise: {premise}\nHypothesis: {hypothesis}"
        )
        self.model = None
        self.init_model(model_path)

    def get_scores(
            self, 
            articles: list[str],
            summaries: list[str]) -> list[float]:
        """
        Takes in a list of articles and their respective summaries and returns 
        hhem scores for all. Assumes articles are aligned by index with 
        summaries

        Args:
            articles (list[str]): List of source articles
            summaries (list[str]): List of generated summaries

        Returns:
            list[float]: list of hhem scores for each article summary pair
        
        """
        scores = []
        for article, summary in zip(articles, summaries):
            score = self.get_score(article, summary)
            scores.append(score)
        return scores

    def get_score(self, article: str, summary: str) -> float:
        """
        Takes in an article summary pair and recieves a HHEM score

        Args:
            article (str): Source article
            summary (str): Generated summary of source article
        
        Returns:
           float: HHEM score 
        """
        score = self.predict(article, summary)
        return score

    def predict(self, article: str, summary: str) -> float:
        """
        Takes in an article and summary, injects the article and summary into
        a Premise Hypothesis prompt, tokenizes the prompt, feeds the prompt into
        the HHEM model, and process the raw output into a singular score

        Args:
            article (str): Source Article
            summary (str): Generated summary of source article

        Returns:
            float: HHEM score
        """
        input = [self.prompt.format(premise=article, hypothesis=summary)]
        #Tokenizer
        #Setup model for prediction not training
        #Return the output logits
        #Process raw logits
        #score = self.process_raw_output(raw_output)
        pass

    def process_raw_output(self, raw_output) -> float:
        """
        Takes in the raw HHEM output, manipulates the tensor, applies softmax, 
        and returns the usable HHEM score

        Args:
            raw_output (torch.float): raw output from HHEM model

        Returns:
            float: HHEM score
        """
        # Process the raw logits into list of float?
        # Select Logits we want
        # Apply softmax
        # return list of floats
        pass

    def init_model(self, model_path: str):
        """
        Initializes the HHEM model 
        """
        pass